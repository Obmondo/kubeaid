{{- if (.Values.global).enableClusterAutoscaler }}

{{/*
  All the replicas within a MachineDeployment will reside in the same Availability Zone.

  To ensure that the worker machines are spread across failure domains, per node-group, we need to
  create N MachineDeployment for your N failure domains, scaling them independently.
  Resiliency to failures comes from having multiple MachineDeployment. 
*/}}
{{- $failureDomains := list "a" "b" "c" }}

{{- range $nodeGroupIndex, $nodeGroup := $.Values.nodeGroups }}
{{- range $failureDomainIndex, $failureDomain := $failureDomains }}
---

{{/* Calculate the Failure Domain specific min size. */}}
  {{- $baseMinSizePerFD := (div $nodeGroup.minSize (len $failureDomains)) }}

  {{- $fdSpecificExtraMinSize := 0 }}

    {{- if (and (eq $failureDomain "a") (ge (mod $nodeGroup.minSize 3) 1))}}
    {{- $fdSpecificExtraMinSize = 1 }}
    {{- end }}

    {{- if (and (eq $failureDomain "b") (ge (mod $nodeGroup.minSize 3) 2))}}
    {{- $fdSpecificExtraMinSize = 1 }}
    {{- end }}

  {{- $fdSpecificMinSize := (add $baseMinSizePerFD $fdSpecificExtraMinSize) }}

{{/* Calculate the Failure Domain specific max size. */}}
  {{- $baseMaxSizePerFD := (div $nodeGroup.maxSize (len $failureDomains)) }}

  {{- $fdSpecificExtraMaxSize := 0 }}

    {{- if (and (eq $failureDomain "a") (ge (mod $nodeGroup.maxSize 3) 1))}}
    {{- $fdSpecificExtraMaxSize = 1 }}
    {{- end }}

    {{- if (and (eq $failureDomain "b") (ge (mod $nodeGroup.maxSize 3) 2))}}
    {{- $fdSpecificExtraMaxSize = 1 }}
    {{- end }}

  {{- $fdSpecificMaxSize := (add $baseMaxSizePerFD $fdSpecificExtraMaxSize) }}

apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  name: {{ printf "%s-%s-%s" $.Values.global.clusterName $nodeGroup.name $failureDomain }}
  annotations:
    cluster.x-k8s.io/cluster-api-autoscaler-node-group-min-size: {{ $fdSpecificMinSize | quote }}
    cluster.x-k8s.io/cluster-api-autoscaler-node-group-max-size: {{ $fdSpecificMaxSize | quote }}
    capacity.cluster-autoscaler.kubernetes.io/memory: "{{ $nodeGroup.memory }}G"
    capacity.cluster-autoscaler.kubernetes.io/cpu: "{{ $nodeGroup.cpu }}"
    capacity.cluster-autoscaler.kubernetes.io/ephemeral-disk: "{{ $nodeGroup.rootVolumeSize | default 35 }}Gi"
    capacity.cluster-autoscaler.kubernetes.io/maxPods: "500"
    capacity.cluster-autoscaler.kubernetes.io/labels: "{{- $labels := list }}{{- range $key, $value := $nodeGroup.labels }}{{- $labels = append $labels (printf "%s=%s" $key $value) }}{{- end }}{{- join "," $labels }}"
    capacity.cluster-autoscaler.kubernetes.io/taints: "{{- $taints := list }}{{- range $taint := $nodeGroup.taints }}{{- $taints = append $taints (printf "%s=%s:%s" $taint.key $taint.value $taint.effect) }}{{- end }}{{- join "," $taints }}"
spec:
  clusterName: {{ $.Values.global.clusterName }}
  replicas: {{ $fdSpecificMinSize }}
  template:
    {{- if $nodeGroup.labels }}
    metadata:
      # Label should meet one of the following criterias to propagate to Node :
      #
      # (1) Has node-role.kubernetes.io as prefix.
      # (2) Belongs to node-restriction.kubernetes.io domain.
      # (3) Belongs to node.cluster.x-k8s.io domain.
      #
      # REFER : https://cluster-api.sigs.k8s.io/developer/architecture/controllers/metadata-propagation#machine
      labels: {{- toYaml $nodeGroup.labels | nindent 8 }}
    {{- end }}

    spec:
      clusterName: {{ $.Values.global.clusterName }}
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: {{ printf "%s-%s" $.Values.global.clusterName $nodeGroup.name }}
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta2
        kind: AWSMachineTemplate
        name: {{ printf "%s-%s" $.Values.global.clusterName $nodeGroup.name }}
      failureDomain: {{ printf "%s%s" $.Values.region $failureDomain | quote }}
      version: {{ $.Values.global.kubernetes.version }}
{{- end }}
{{- end }}
{{- end }}
